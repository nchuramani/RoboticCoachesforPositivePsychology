import numpy
from GDM_Imagine_Dimensional.episodic_gwr import EpisodicGWR
from GDM_Imagine_Dimensional import gtls
import numpy as np
import re
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}
import tensorflow as tf
tf.get_logger().setLevel('ERROR')
from PIL import Image
import shutil
def sort_nicely(l):
    """ Sort the given list in the way that humans expect.
    """

    convert = lambda text: int(text) if text.isdigit() else text
    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]
    l.sort(key=alphanum_key)
    return l
# --------------------------------------------------------------------
# -HELPERS------------------------------------------------------------
# --------------------------------------------------------------------
def normalize_image(img, maximum):
    """
    Normalizes all pixels to values between 0 and maximum.

    @param img: numpy array
    @param maximum: scalar value

    @return numpy array of same size as img
    """
    img /= img.max() / maximum
    return img


def save_image(img_array, path):
    """
    Saves an image from a three-dimensional numpy array under path.

    @param img_array: two-dimensional numpy array
    @param path: string
    """
    img = Image.fromarray(img_array.astype('uint8'))
    img = img.convert('RGB')
    img.save(path)


def get_image_array(path, image_size=None):
    """
    Reads image from file and transforms it to numpy array.

    @param path: string
    @param image_size: (optional) size of the image

    @param img_array: numpy array
    """
    if image_size == None:
        return np.asarray(Image.open(path)).astype(np.float32)
    return np.asarray(Image.open(path).resize(image_size)).astype(np.float32)


def get_generated_images(path, p=96):
    """
    Cuts generated images from image saved in network output format.

    @param path: path to image to cut generated images from.

    @return: numpy array of shape 49x96x96x3
    """
    img = get_image_array(path)
    res = []
    for r in range(7):
        for c in range(7):
            single_image = img[r * p:(r + 1) * p, p * (c + 3):p * (c + 4)]
            res.append(single_image)
    return np.asarray(res)


def tile_to_square(images):
    """
    Transforms numpy array of 49x96x96 to numpy array of 672x672 by tiling.

    @param images: numpy array of shape 49x96x96

    @return: numpy array of shape 672x672
    """
    # Build final image from components
    frame = np.zeros([96 * 7, 96 * 7])
    for index, image in enumerate(images):
        index_column = index % 7
        index_row = index // 7
        frame[(index_row * 96):((index_row + 1) * 96), (index_column * 96):((index_column + 1) * 96)] = image
    return frame


def save_generated_output(inp, generated_outp, path, valence, arousal):
    """
    Save the output generated by the network.
    """
    for i in range(len(generated_outp)):
        save_path, ext = path.split('.')
        if not os.path.exists(save_path):
            os.makedirs(save_path)

        save_image((generated_outp[i] + 1) * 255 / 2, save_path + "/ar_" + str(arousal[i][0]) + "_val_" + str(valence[i][0]) + "." + str(ext))


def load_image_as_network_input(image_path):
    """
    Load image and normalize it to pixel values in [-1,1].

    @param image_path: path to image (string)

    @return: numpy array of size 96x96x3
    """
    image = get_image_array(image_path, image_size=(96, 96))
    image = normalize_image(image, 2)
    return image - 1


# --------------------------------------------------------------------
# -MAIN METHODS-------------------------------------------------------
# --------------------------------------------------------------------

def save_frames(path_to_dir, path_to_out_dir):
    from utils import imageProcessingUtil

    # files = os.listdir(path_to_dir)
    files_already = os.listdir(path_to_out_dir)

    files = [f for f in os.listdir(path_to_dir) if not f in files_already]
    for file in files:
        open_path = path_to_dir + file
        frame = np.asarray(Image.open(open_path)).astype(np.float32)
        imageProcessing = imageProcessingUtil()
        facePoints, face = imageProcessing.detectFace(frame)
        if not len(face) == 0:
            # pre-process the face
            face = imageProcessing.preProcess(face, (96, 96))
        save_path = path_to_out_dir + file
        face = face * 255.0
        save_image(face, save_path)

def generate_images(loadPath, valence, arousal, path_to_dir, path_to_out_dir):
    with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True)) as sess:
        # restore graph
        new_saver = tf.compat.v1.train.import_meta_graph(loadPath + '/01_model.meta')
        new_saver.restore(sess, tf.compat.v1.train.latest_checkpoint(loadPath))
        graph = tf.compat.v1.get_default_graph()

        arousal_tensor = graph.get_tensor_by_name("arousal_labels:0")
        valence_tensor = graph.get_tensor_by_name("valence_labels:0")
        images_tensor = graph.get_tensor_by_name("input_images:0")

        # load input
        files_already = os.listdir(path_to_out_dir)
        files = [f for f in os.listdir(path_to_dir) if not f in files_already]

        for file in files:
            i = load_image_as_network_input(path_to_dir + file).reshape((1, 96, 96, 3))
            query_images = np.tile(i, (49, 1, 1, 1))

            # create input for net
            feed_dict = {arousal_tensor: arousal, valence_tensor: valence, images_tensor: query_images}
            op_to_restore = sess.graph.get_tensor_by_name("generator/Tanh:0")
            # run
            x = sess.run(op_to_restore, feed_dict)
            # save
            save_generated_output(i, x, path_to_out_dir + file, valence=valence, arousal=arousal)


def generate_encodings(loadPath, path_to_out_dir, test=False):
    dataX = []
    dataY_arousal = []
    dataY_valence = []
    with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True)) as sess:
        # restore graph
        new_saver = tf.compat.v1.train.import_meta_graph(loadPath + '/01_model.meta')
        new_saver.restore(sess, tf.compat.v1.train.latest_checkpoint(loadPath))
        graph = tf.compat.v1.get_default_graph()

        arousal_tensor = graph.get_tensor_by_name("arousal_labels:0")
        valence_tensor = graph.get_tensor_by_name("valence_labels:0")
        images_tensor = graph.get_tensor_by_name("input_images:0")

        # load input
        files = os.listdir(path_to_out_dir)
        if not test:
            for file in files:
                arousal = []
                valence = []
                query_images = []
                imgs = os.listdir(path_to_out_dir + file)
                for img in imgs:
                    name = img.split(".jp")[0]
                    _, ar, _, val = name.split("_")
                    arousal.append(float(ar))
                    valence.append(float(val))
                    query_images.append(load_image_as_network_input(path_to_out_dir + file + "/" + img).reshape((1, 96, 96, 3)))
                arousal = np.array(arousal).reshape((49, 1))
                valence = np.array(valence).reshape((49, 1))
                query_images = np.array(query_images).reshape((49, 96, 96, 3))

                # create input for net
                feed_dict = {arousal_tensor: arousal, valence_tensor: valence, images_tensor: query_images}
                # Extract Encoder output
                encoder_out = sess.graph.get_tensor_by_name("encoder/Tanh:0")
                # run
                encodings = sess.run(encoder_out, feed_dict)

                if  dataX == []:
                    dataX = encodings
                    dataY_arousal = arousal
                    dataY_valence = valence
                else:
                    dataX = np.vstack([dataX, encodings])
                    dataY_arousal = np.vstack([dataY_arousal, arousal])
                    dataY_valence = np.vstack([dataY_valence, valence])
            return dataX, np.hstack([dataY_valence, dataY_arousal])
        else:
            if len(files) < 49:
                to_fill = 49 - len(files)
                files = numpy.concatenate([files, [files[i] for i in numpy.random.randint(0, len(files), to_fill)]])
            query_images = []
            for file in files:
                query_images.append(load_image_as_network_input(path_to_out_dir + file).reshape((1, 96, 96, 3)))
            query_images = np.array(query_images).reshape((len(query_images), 96, 96, 3))

            # create input for net
            feed_dict = {images_tensor: query_images}
            encoder_out = sess.graph.get_tensor_by_name("encoder/Tanh:0")
            encodings = sess.run(encoder_out, feed_dict)
            if dataX == []:
                dataX = encodings
            else:
                dataX = np.vstack([dataX, encodings])
            return dataX
def apply_network_to_images_of_dir(loadPath, path_to_dir, path_to_out_dir):
    """
    Applies the trained network to all images found in path_to_dir for 49 emotions respectively.
    Saves the output in path_to_out_dir.

    @param path_to_dir: path to existing directory (string)
    @param path_to_out_dir: path to existing directory (string)
    """

    # valence
    valence = np.arange(0.75, -0.751, -0.25)
    valence = np.repeat(valence, 7).reshape((49, 1))

    # arousal
    arousal = [np.arange(0.75, -0.751, -0.25)]
    arousal = np.repeat(arousal, 7, axis=0)
    arousal = np.asarray([item for sublist in arousal for item in sublist]).reshape((49, 1))
    generate_images(loadPath, valence, arousal, path_to_dir, path_to_out_dir)
    return generate_encodings(loadPath, path_to_out_dir)



def select_frames_to_imagine(path_to_dir, path_to_out_dir, size):
    files = np.random.choice(os.listdir(path_to_dir), size, replace=True)
    for file in files:
        shutil.copyfile(path_to_dir + file, path_to_out_dir + file)


def train_GDM(data, labels, trained_GWRs, train_replay, train_imagine):
    def replay_samples(net, size):
        samples = np.zeros(size, dtype=int)
        r_weights = np.zeros((net.num_nodes, size, net.dimension))
        r_labels = np.zeros((net.num_nodes, 2, size))
        for i in range(0, net.num_nodes):
            for r in range(0, size):
                if r == 0:
                    samples[r] = i
                else:
                    samples[r] = np.argmax(net.temporal[int(samples[r - 1]), :])
                r_weights[i, r] = net.weights[int(samples[r])][0]
                r_labels[i, 0, r] = net.alabelsValence[int(samples[r])]
                r_labels[i, 1, r] = net.alabelsArousal[int(samples[r])]
        return r_weights, r_labels

    print("Replay: " + str(train_replay))
    print("Imagination: " + str(train_imagine))

    '''
    Episodic-GWR supports multi-class neurons.
    Set the number of label classes per neuron and possible labels per class
    e.g. e_labels = [50, 10]
    is two labels per neuron, one with 50 and the other with 10 classes.
    Setting the n. of classes is done for experimental control but it is not
    necessary for associative GWR learning.
    '''
    # Setting up format for Episodic and Semantic Memory labelling
    # e_labels = [labelsize, labelsize]
    # s_labels = [labelsize]
    # Training Data
    ds_vectors = data
    # Training Labels
    ds_labels = labels
    # ds_labels = np.zeros((len(e_labels), len(dataY)))
    # ds_labels[0] = dataY
    # ds_labels[1] = dataY
    # Number of context descriptors; Set to zero for frame-based evaluations.
    num_context = 0

    a_threshold = [0.8, 0.7]
    h_thresholds = [0.2, 0.2]
    beta = 0.7
    e_learning_rates = [0.087, 0.032]

    s_learning_rates = [0.087, 0.032]

    context = True

    # Initialising Episodic and Semantic Memory GWR Models.
    if trained_GWRs[0] is None:
        # Initialisint Episodic Memory
        g_episodic = EpisodicGWR()
        # Higher Max-nodes and lower age allow for faster learning with pattern-separated representations.
        g_episodic.init_network(data, ds_labels, num_context, max_nodes=len(data), age=600)
        # Initialising Semantic Memory
        g_semantic = EpisodicGWR()
        # Lower Max-nodes and higher age allow for slower learning with pattern-complete representations.
        g_semantic.init_network(data, ds_labels, num_context, max_nodes=len(data)//2, age=1200)

    else:
        # Loading trained models for subsequent training runs.
        g_episodic, g_semantic = trained_GWRs

    """ Incremental training hyper-parameters """

    # Epochs per sample for incremental learning
    epochs = 6
    # Initialising experienced episodes to Zero.
    n_episodes = 0
    # Number of samples per epoch
    batch_size = 5

    # Replay parameters; With num_context = 0, RNATs size set to 1, that is, only looking at previous BMU.
    # Size of RNATs
    replay_size = (num_context * 2) + 1
    replay_weights = []
    replay_labels = []

    """##############################################################################################"""
    """ ##################################  Logging Parameters  #####################################"""
    """##############################################################################################"""

    print("GDM Parameters LOG")
    print("Number of Epochs: " + str(epochs))
    print("Number of Contexts: " + str(num_context))
    print("Activation Thresholds: [" + str(a_threshold[0]) + ", " + str(a_threshold[1]) + "]")
    print("Habituation Thresholds: [" + str(h_thresholds[0]) + ", " + str(h_thresholds[1]) + "]")
    print("Episodic lr: [" + str(e_learning_rates[0]) + ", " + str(e_learning_rates[1]) + "]")
    print("Semantic lr: [" + str(s_learning_rates[0]) + ", " + str(s_learning_rates[1]) + "]")
    print("Batch Size: " + str(batch_size))
    print("GDM Parameters LOG")


    """##############################################################################################"""
    """ ############################   Running Training of Memories  ################################"""
    """##############################################################################################"""

    for s in range(0, ds_vectors.shape[0], batch_size):
        print("Training Episodic Regular")
        g_episodic.train_egwr(ds_vectors[s:s + batch_size],
                              ds_labels[s:s + batch_size],
                              epochs, a_threshold[0], beta, e_learning_rates,
                              context, hab_threshold=h_thresholds[0], regulated=0)
        e_weights, ccc, e_labels = g_episodic.test_av(ds_vectors[s:s + batch_size], ds_labels[s:s + batch_size],
                                                         test_accuracy=True)
        print("Training Semantic Regular")
        g_semantic.train_egwr(e_weights, ds_labels[s:s + batch_size],
                              epochs, a_threshold[1], beta, s_learning_rates,
                              context=False, hab_threshold=h_thresholds[1], regulated=1)

        # Running Pseudo-Replay  #######################################"""
        if n_episodes > 0:
            # Replay pseudo-samples
            print("Training Episodic Replay")
            # Episodic Pseudo-Replay
            g_episodic.train_egwr(replay_weights, replay_labels,
                                  epochs//3, a_threshold[0], beta,
                                  e_learning_rates, context=False, hab_threshold=h_thresholds[0], regulated=0)
            print("Training Semantic Replay")
            # Semantic Pseudo-Replay
            g_semantic.train_egwr(replay_weights, replay_labels,
                                  epochs//3, a_threshold[1], beta,
                                      s_learning_rates, context=False, hab_threshold=h_thresholds[1], regulated=1)


        # Generating Pseudo-Samples
        replay_weights, replay_labels = replay_samples(g_episodic, replay_size)
        replay_weights = numpy.squeeze(replay_weights)
        replay_labels = numpy.squeeze(replay_labels)
        n_episodes += 1

    # Evaluation with only Current Data
    e_weights, e_ccc, e_labels = g_episodic.test_av(ds_vectors, ds_labels, test_accuracy=True)
    s_weights, s_ccc, s_labels = g_semantic.test_av(e_weights, ds_labels, test_accuracy=True)

    return (g_episodic, g_semantic), (e_ccc, s_ccc)


def annotate_GDM(trained_GWRs, test_data):
    g_episodic, g_semantic = trained_GWRs

    # Annotations from Episodic
    e_valence, e_arousal = g_episodic.annotate(test_data)

    # Annotations from Semantic
    s_valence, s_arousal = g_semantic.annotate(test_data)

    return [e_valence, e_arousal], [s_valence, s_arousal]

if __name__ == "__main__":

    # Running the Experiment Loop for all class_orders.
    save_path = "/home/nc528/Desktop/testing"
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    # Running GDM + Imagination condition.
    replay = True
    imagine = True
    # Initialising Episodic and Semantic Memory models from None.
    trained_GWRs = (None, None)
    # LOAD PATHS FOR MODEL AND IMAGES
    CAAE_LoadPath = "/home/nc528/Desktop/Projects/FaceEdit/ContinuousImagination/checkpoint"
    images_path_temp = "/home/nc528/Desktop/Projects/FaceEdit/ContinuousImagination/test_images_faces_to_imagine/"
    images_path_faces = "/home/nc528/Desktop/Projects/FaceEdit/ContinuousImagination/test_images_faces/"
    # images_path = "/home/nc528/Desktop/Projects/FaceEdit/ContinuousImagination/test_images/"
    images_generated_path = "/home/nc528/Desktop/Projects/FaceEdit/ContinuousImagination/test_images_faces_edited/"
    if not os.path.exists(images_path_temp):
        os.makedirs(images_path_temp)
    if not os.path.exists(images_generated_path):
        os.makedirs(images_generated_path)

    # save_frames(datasetTrainFolder, images_path_faces)
    # select_frames_to_imagine(images_path_faces, images_path_temp, size=8)
    novel_data, novel_labels = apply_network_to_images_of_dir(loadPath=CAAE_LoadPath, path_to_dir=images_path_temp,
                                                              path_to_out_dir=images_generated_path)

    # Training with Novel Data
    trained_GWRs, cccs = train_GDM(data=novel_data, labels=novel_labels, trained_GWRs=trained_GWRs,
                                        train_replay=replay, train_imagine=imagine)


    # Saving Trained models for each subject
    save_models_path =save_path
    if not os.path.exists(save_models_path):
        os.makedirs(save_models_path)
    gtls.export_network(save_models_path + "/GDM_E", trained_GWRs[0])
    gtls.export_network(save_models_path + "/GDM_S", trained_GWRs[1])


    # Annotate User Data
    encodings = generate_encodings(CAAE_LoadPath, images_path_faces, test=True)
    episodic_results, semantic_results = annotate_GDM(trained_GWRs, encodings)
    print("Episodic Results")
    print("Valence: ", episodic_results[0])
    print("Arousal: ", episodic_results[1])
    print("Semantic Results")
    print("Valence: ", semantic_results[0])
    print("Arousal: ", semantic_results[1])
