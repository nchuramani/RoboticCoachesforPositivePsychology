"""
Emotion Recognition - Vision-Frame-Based Face Channel

__author__ = "Pablo Barros"

__version__ = "0.1"
__maintainer__ = "Pablo Barros"
__email__ = "barros@informatik.uni-hamburg.de"

More information about the implementation of the model:

Barros, P., Churamani, N., & Sciutti, A. (2020). The FaceChannel: A Light-weight Deep Neural Network for Facial Expression Recognition. arXiv preprint arXiv:2004.08195.

Barros, P., & Wermter, S. (2016). Developing crossmodal expression recognition based on a deep neural model. Adaptive behavior, 24(5), 373-396.
http://journals.sagepub.com/doi/full/10.1177/1059712316664017

"""

import cv2
from Utils import imageProcessingUtil, modelDictionary, modelLoader, GUIController
import numpy

import tensorflow as tf
config = tf.ConfigProto()
config.gpu_options.allow_growth=True
sess = tf.Session(config=config)


finalImageSize = (1024,768) # Size of the final image generated by the demo
categoricalInitialPosition = 460 # Initial position for adding the categorical graph in the final image
faceSize = (64,64) # Input size for both models: categorical and dimensional
faceDetectionMaximumFrequency = 20 # Frequency that a face will be detected: every X frames.

modelDimensional = modelLoader.modelLoader(modelDictionary.DimensionalModel)
modelCategorical = modelLoader.modelLoader(modelDictionary.CategoricaModel)

imageProcessing = imageProcessingUtil.imageProcessingUtil()

GUIController = GUIController.GUIController()

cap = cv2.VideoCapture(0)

arousals = []
valences = []


cap.open(0)

if cap.isOpened():  # try to get the first frame
    rval, f = cap.read()
else:
    rval = False


# video = "/home/pablo/Documents/Datasets/wristbot/videos/S002_G1_bl.mp4"
#
# cap = cv2.VideoCapture(video) #open the video

frames = 0
while(True):
    # Capture frame-by-frame

        rval, frame = cap.read()

        # frame = cv2.resize(frame,(640,480))

        # detect faces
        facePoints, face = imageProcessing.detectFace(frame)

        # create display image and copy the captured frame to it
        image = numpy.zeros((finalImageSize[1], finalImageSize[0], 3), numpy.uint8)
        image[0:480, 0:640] = frame
        frame = image

         # If a face is detected
        if not len(face) == 0:
            # pre-process the face
            face = imageProcessing.preProcess(face, faceSize)

            # Obtain dimensional classification
            dimensionalRecognition = numpy.array(modelDimensional.classify(face))

            #Obtain Categorical classification
            categoricalRecognition = modelCategorical.classify(face)[0]

            # Print the square around the categorical face
            frame = GUIController.createDetectedFacGUI(frame,facePoints,modelDictionary=modelCategorical.modelDictionary, categoricalClassificationReport=categoricalRecognition)

            # # # Create the categorical classification
            frame = GUIController.createCategoricalEmotionGUI(categoricalRecognition, frame,
                                                              modelCategorical.modelDictionary,
                                                              initialPosition=categoricalInitialPosition)
            # Create the dimensional graph
            frame = GUIController.createDimensionalEmotionGUI(dimensionalRecognition, frame, categoricalReport=[], categoricalDictionary=None)

            if len(arousals) > 100:
                arousals.pop(0)
                valences.pop(0)

            #Create dimensional plot
            arousals.append(dimensionalRecognition[0][0][0])
            valences.append(dimensionalRecognition[1][0][0])

            frame = GUIController.createDimensionalPlotGUI(arousals, valences, frame)


        #Display the resulting frame
        cv2.imshow('frame',frame)

        # frames = frames+1
        # cv2.imwrite("/home/pablo/Documents/Datasets/wristbot/frames/"+str(frames)+".png", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

# When everything done, release the capture
cap.release()
cv2.destroyAllWindows()